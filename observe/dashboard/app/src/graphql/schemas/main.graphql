# When adding new scalars, be sure to include them in the code generator config (codegen.yml),
# so that it knows how to convert these GraphQL types into typescript types
# Additional scalars are available in the graphql-scalars package. If these are used, their resolvers must be imported in schema.ts

# Note: use Float type for numbers larger than 32 bits
enum Permission {
  MANAGE_INTERNAL # aka WhyLabs only
  MANAGE_ORG
  MANAGE_DATASETS
  MANAGE_MONITORS
  MANAGE_ACTIONS
  MANAGE_API_TOKENS
  MANAGE_DASHBOARDS
  VIEW_DATA
}

"""
Directive that allows specifying access control policy for a given field
"""
directive @auth(
  """
  If True, permissions will NOT be checked. This allows explicitly declaring fields that do not require special access rights.
  """
  skipPermissionsCheck: Boolean
  """
  List of permissions required to access this field. User must have all of the specified permissions.
  """
  permissions: [Permission!]
) on FIELD_DEFINITION

# Note: use Private scope for fields/objects that should not be shared among all authenticated users or that depend on user context
enum CacheControlScope {
  PUBLIC
  PRIVATE
}

directive @cacheControl(maxAge: Int, scope: CacheControlScope) on FIELD_DEFINITION | OBJECT | INTERFACE

"""
What entity the event is targeting
(i.e. what was the monitor monitoring when it produced the event)
"""
enum EventTargetType {
  Dataset
  Feature
  Unknown
}

enum EventType {
  NullFraction
  Distribution
  Uniqueness
  DataType
  ThresholdBased
  MissingRecentData
  MissingRecentProfiles
  Unknown
}

enum Algorithm {
  SeasonalARIMA
  StaticThreshold
  Unknown
}

enum WhyLogsMetric {
  DistributionDistance
  MissingValuesRatio
  UniqueCount
  InferredDataType
  Quantile50
  TotalCount
  Min
  Max
  StdDev
  Mean
  Unknown
}

enum EventArchetype {
  Threshold
  DataType
  Unknown
}

input EventFilter {
  id: String
  fromTimestamp: Float
  toTimestamp: Float
  """
  Deprecated field, same effect as `datasetId`
  """
  dataset: String
  """
  ID of the dataset to filter on
  """
  datasetId: String
  tags: [SegmentTagFilter!]
  feature: String
  eventType: EventType
  eventArchetype: EventArchetype
  metric: WhyLogsMetric
  algorithm: Algorithm
  adhocRunId: String
  targetTypes: [EventTargetType!]
}

type MaintenanceBanner {
  """
  Outage/maintenance message. Will be visible to ALL users on the platform.
  """
  message: String!
  """
  Email of the WhyLabs user that set the message.
  Not available to regular users, only WhyLabs employees.
  """
  updatedBy: String! @auth(permissions: [MANAGE_INTERNAL])
  """
  UTC datetime of the last update
  """
  updatedAt: String!
}

type Mutation @cacheControl(scope: PRIVATE)


# Note: cacheControl scope determines how accessible the cache is
# Public - if sessionId factory function is defined during GraphQL server setup (it should be), the cached versions of these fields/objects will be accessible to all authenticated users
# Private - if sessionId factory function is defined, the cached object will only be accessible to the session/user/whatever, as determined by the sessionId factory function,
# and all other requests will go through directives/resolvers and not hit cache (re-computing access right in the process)
type Query @cacheControl(scope: PRIVATE) {
  model(id: String, startTime: Float, endTime: Float): Model @auth
  """
  Fetch the specified models/datasets/projects.
  Fetches all models/datasets/projects if no dataset IDs argument was supplied.
  """
  models(datasetIDs: [String!], resourceTags: [CustomTagFilter!], resourceType: [ModelType!], onlySecuredLLM: Boolean, searchTerm: String): [Model!]! @auth
  """
  Fetch the maintenance banner. Used to display information about outages/maintenance, if any.
  """
  maintenanceBanner: MaintenanceBanner @auth(skipPermissionsCheck: true)
}


enum SubscriptionTier {
  PAID
  FREE
  AWS_MARKETPLACE
  SUBSCRIPTION
  UNKNOWN
}

enum ValueSource {
  User
  Learned
  Default
  Unknown
}

type EventParam {
  value: Float!
  source: ValueSource!
}

type ThresholdEventExplanation {
  minThreshold: EventParam
  maxThreshold: EventParam
  eventName: String! @deprecated(reason: "Duplicate of event type, do not use")
  message: String!
    @deprecated(
      reason: "Messages will not be populated on the backend going forward. Human-friendly alert descriptions can be generated and localized in the front end."
    )
  observedValue: Float!
  expectedValue: Float! @deprecated(reason: "Not human interpretable, do not surface in UI")
}

union EventExplanation = DataTypeEventExplanation | ThresholdEventExplanation | BaseEventExplanation

interface DataQualityEvent {
  id: String!
  runId: String
  orgId: String!
  datasetId: String!
  """
  If the event is an Alert, this flag determines whether it was designated as a False Alarm by a user.
  """
  isFalseAlarm: Boolean
  sessionId: String
  timestamp: Float!
    @deprecated(
      reason: "This field refers to datasetTimestamp. Please use either creationTimestamp or datasetTimestamp explicitly."
    )
  # time when event was generated
  creationTimestamp: Float!
  # time when the batch of data that the event is based on was generated
  datasetTimestamp: Float!
  type: EventType! @deprecated
  target: EventTargetType!
  category: AlertCategory!
  archetype: EventArchetype! @deprecated
  algorithm: Algorithm!
  segment: String @deprecated(reason: "Segments have no name, use tags instead")
  tags: [SegmentTag!]
  feature: String!
  metric: WhyLogsMetric!
  severity: Float! @deprecated(reason: "Currently not a human-interpretable parameter, do not expose in UI")
  explanation: EventExplanation!
}

type BaseEventExplanation {
  """
  Contains JSON body of the explanation that we couldn't parse, if any.
  """
  jsonBody: String
}

type DataQualityEventBase implements DataQualityEvent {
  id: String!
  runId: String
  orgId: String!
  datasetId: String!
  """
  If the event is an Alert, this flag determines whether it was designated as a False Alarm by a user.
  """
  isFalseAlarm: Boolean
  sessionId: String
  timestamp: Float! @deprecated(reason: "Use datasetTimestamp or creationTimestamp instead")
  creationTimestamp: Float!
  datasetTimestamp: Float!
  type: EventType!
  target: EventTargetType!
  category: AlertCategory!
  archetype: EventArchetype!
  algorithm: Algorithm!
  segment: String
  tags: [SegmentTag!]
  feature: String!
  metric: WhyLogsMetric!
  severity: Float!
  explanation: EventExplanation!
}

type ThresholdEvent implements DataQualityEvent {
  id: String!
  runId: String
  orgId: String!
  datasetId: String!
  """
  If the event is an Alert, this flag determines whether it was designated as a False Alarm by a user.
  """
  isFalseAlarm: Boolean
  sessionId: String
  timestamp: Float! @deprecated(reason: "Use datasetTimestamp or creationTimestamp instead")
  creationTimestamp: Float!
  datasetTimestamp: Float!
  type: EventType!
  target: EventTargetType!
  category: AlertCategory!
  archetype: EventArchetype!
  algorithm: Algorithm!
  segment: String
  tags: [SegmentTag!]
  feature: String!
  metric: WhyLogsMetric!
  severity: Float!
  # fields specific to ThresholdEvents
  explanation: ThresholdEventExplanation!
}

type DataTypeEventExplanation {
  value: FeatureType!
  previousValue: FeatureType!
  eventName: String! @deprecated(reason: "Duplicate of event type, do not use")
  message: String!
    @deprecated(
      reason: "Messages will not be populated on the backend going forward. Human-friendly alert descriptions can be generated and localized in the front end."
    )
}

type DataTypeEvent implements DataQualityEvent {
  id: String!
  runId: String
  orgId: String!
  datasetId: String!
  """
  If the event is an Alert, this flag determines whether it was designated as a False Alarm by a user.
  """
  isFalseAlarm: Boolean
  sessionId: String
  timestamp: Float! @deprecated(reason: "Use datasetTimestamp or creationTimestamp instead")
  creationTimestamp: Float!
  datasetTimestamp: Float!
  type: EventType!
  target: EventTargetType!
  category: AlertCategory!
  archetype: EventArchetype!
  algorithm: Algorithm!
  segment: String
  tags: [SegmentTag!]
  feature: String!
  metric: WhyLogsMetric!
  severity: Float!
  # fields specific to DataTypeEvents
  explanation: DataTypeEventExplanation!
}

type AuditLog {
  timestamp: Float!
  userId: String!
  userName: String!
  organizationId: String!
  organizationName: String!
  datasetId: String!
  datasetName: String!
  segmentTags: [SegmentTag!]
  feature: String
  resource: String!
  diff: String!
}

enum TimePeriod {
  INDIVIDUAL
  P1M
  P1W
  P1D
  PT1H
  UNKNOWN
  ALL
}

type ROC {
  values: [[Float!]!]!
}

type CalibrationCurve {
  values: [[Float]!]!
}

type ConfusionMatrix {
  labels: [String!]!
  counts: [[Float!]!]!
  targetField: String
  predictionsField: String
  scoreField: String
}

type FilteredFeatureSketches {
  totalCount: Float!
  totalDiscrete: Float!
  totalNonDiscrete: Float!
  results: [FeatureSketch!]!
}

type InsightEntry {
  name: String!
  column: String!
  description: String
  message: String!
  metrics: InsightMetricResult!
}

type InsightMetricResult {
  most_freq_estimate: Int
  most_freq_value: String
  mean: Float
  counts_total: Int
  counts_null: Int
  types_boolean: Int
  types_fractional: Int
  types_integral: Int
  types_tensor: Int
  types_object: Int
  min_value: Float
  max_value: Float
  uniqueness: Float
}

input FeatureSketchFilter {
  substring: String
  substrings: [String!]
  featureNames: [String!]
  featureName: String
  includeDiscrete: Boolean = True
  includeNonDiscrete: Boolean = True
}

type BatchMetadata {
  datasetId: String!
  tags: [SegmentTag!]!
  timestamp: Float!
  """
  endTimestamp is only available when getting batches by timestamp
  """
  endTimestamp: Float
  inputCount: Float!
  outputCount: Float!
  batchFrequency: TimePeriod!

  """
  Gets all the FeatureSketches associated with the given Batch.
  May be horribly inefficient when the number of batches is large, as it looks up sketches by timestamp match rather than a time range at the moment.
  Avoid queries like `model > batches(from: 123, to: 123) > sketches` until this flow is optimized. `model > batch(timestamp: 123) > sketches` is ok.

  Set histogramSplitPoints to specify the desired histogram bin edges.
  NOTE: min and max will be added automatically at query time, because they depend on the profile for which the histogram will be generated. These split points should not include min/max.
  E.g., if you'd like to split data into bins with edges [min, 5, 10, max], set this argument to [5, 10]
  """
  sketches(
    offset: Int = 0
    limit: Int = 0
    filter: FeatureSketchFilter
    histogramSplitPoints: [Float!]
    """
    If True, empty sketches will be excluded from the results of reference and single batch sketches
    """
    excludeEmpty: Boolean
  ): FilteredFeatureSketches!
}

type DateRange {
  fromTimestamp: Float!
  toTimestamp: Float!
}

input FeatureFilter {
  substring: String
  substrings: [String!]
  alertTypes: [EventType!]
  anomalyCategories: [AlertCategory!]
  includeDiscrete: Boolean = True
  includeNonDiscrete: Boolean = True

  # time range is important to specify, as some filters (such as hasAlerts) are time-dependent
  fromTimestamp: Float = 0
  toTimestamp: Float
  # use with care as it is expensive
  excludeEmpty: Boolean = False
}

type FilteredFeatures {
  results: [Feature!]!
  totalCount: Float!
}

enum FeatureSortBy {
  Name
  AbsoluteWeight
  AlertCount
  Weight
  WeightRank
}

enum SortDirection {
  ASC
  DESC
}

input FilteredFeaturesSort {
  by: FeatureSortBy!
  direction: SortDirection!
}

type DataAvailability {
  """
  Whether the dataset has any data
  """
  hasData: Boolean
  """
  Timestamp of the oldest available batch of data for the dataset
  """
  oldestTimestamp: Float
  """
  Timestamp of the latest (most recent) available batch of data for the dataset
  """
  latestTimestamp: Float
}

type DataLineage {
  oldestProfileTimestamp: Float
  latestProfileTimestamp: Float
}

type EntitySchemaColumnCounts {
  total: Int!
  discrete: Int!
  nonDiscrete: Int!
}

type EntitySchema {
  """
  Schema for inputs
  """
  inputs: [EntityColumnSchema!]
  """
  Schema for outputs
  """
  outputs: [EntityColumnSchema!]
  """
  Schema for all columns
  """
  columns: [EntityColumnSchema!]
  """
  Whether the dataset has columns
  """
  hasColumns: Boolean!
  """
  Whether the dataset has outputs
  """
  hasOutputs: Boolean!
  """
  Whether the dataset has inputs
  """
  hasInputs: Boolean!
  """
  Counts for input columns
  """
  inputCounts: EntitySchemaColumnCounts!
  """
  Counts for output columns
  """
  outputCounts: EntitySchemaColumnCounts!
}

enum AssetCategory {
  MODEL
  DATA
  LLM
}

interface Dataset {
  id: String!
  datasetId: String!
  name: String!
  tags: [SegmentTag!]!
  resourceTags: [CustomTag!]!
  creationTime: Float
  modelType: ModelType!
  assetCategory: AssetCategory
  batchFrequency: TimePeriod!
  batch(datasetTimestamp: Float!): BatchMetadata
  batches(from: Float = 0, to: Float, timestamps: [Float!]): [BatchMetadata!]!
  batchDateRanges(timestamps: [Float!]!): [DateRange!]!
  output(name: String!): Feature
  outputs: [Feature!]!
  filteredOutputs(
    offset: Int = 0
    limit: Int = 0
    filter: FeatureFilter!
    sort: FilteredFeaturesSort
  ): FilteredFeatures!
  feature(name: String!): Feature
  features(offset: Int = 0, limit: Int = 0): [Feature!]!
    @deprecated(
      reason: "This query returns ALL features in a dataset, which can be thousands. Please use 'filteredFeatures' query instead."
    )
  filteredFeatures(
    offset: Int = 0
    limit: Int = 0
    filter: FeatureFilter!
    sort: FilteredFeaturesSort
  ): FilteredFeatures!
  alertCountsV2(
    fromTimestamp: Float!
    toTimestamp: Float
    groupBy: AnomalyCountGroupBy
    filter: AnomalyOptionalFilter
    granularityInclusion: GranularityInclusion
  ): AlertCategoryCounts @deprecated(reason: "Use anomalyCounts instead - same query, but clearer naming.")
  alerts(filter: EventFilter!): [DataQualityEvent!]! @deprecated(reason: "This query serves Monitor V2 data. Use 'anomalies' query instead")
  latestAlert: DataQualityEvent @deprecated(reason: "This query serves Monitor V2 data. Use 'latestAnomaly' query instead")
  latestAnomaly(monitorIds: [String!], analyzerIds: [String!]): AnalysisResult @deprecated(reason: "No longer supported. Use 'latestAnomalyTimestamp' instead")
  """
  Returns the timestamp of the latest anomaly, if one exists
  """
  latestAnomalyTimestamp(monitorIds: [String!], analyzerIds: [String!]): Float
  events(filter: EventFilter!): [DataQualityEvent!]!
    @deprecated(reason: "This query serves Monitor V2 data. Use 'analysisResults' query instead")
  """
  Available reference profiles that have been uploaded for this dataset
  """
  referenceProfiles(from: Float, to: Float, profileIds: [String!]): [ReferenceProfile!]
  """
  Individual profiles that have been uploaded for this dataset
  """
  individualProfileList(from: Float!, to: Float!, offset: Int, limit: Int): [IndividualProfileItem!]
  """
  Individual profiles that have been uploaded for this dataset
  """
  individualProfiles(retrievalTokens: [String!]!): [IndividualProfile!]
  """
  Constraints list (analyzers json string config) for this dataset
  """
  constraintsList: [String!]
  featureCounts: FeatureCounts
  """
  Information about data availability for this dataset
  """
  dataAvailability: DataAvailability
  """
  Date range of data lineage for this dataset with start and end timestamps fitting the batch bucket
  """
  dataLineage: DataLineage
  """
  Information about entity schema for this dataset
  """
  entitySchema: EntitySchema
  """
  Profile insights for this dataset
  """
  insights(batchProfileTimestamp: Float, referenceProfileId: String, tags: [SegmentTagFilter!]): [InsightEntry!]
}

type FeatureCounts {
  discrete: Int!
  nonDiscrete: Int!
}

enum ModelType {
  # ML asset types
  CLASSIFICATION
  REGRESSION
  EMBEDDINGS
  LLM
  RANKING
  MODEL_OTHER

  # data asset types
  DATA_SOURCE
  DATA_STREAM
  DATA_TRANSFORM
  DATA_OTHER

  # unset asset type
  UNKNOWN
}

type Model implements Dataset {
  id: String!
  datasetId: String!
  name: String!
  tags: [SegmentTag!]!
  resourceTags: [CustomTag!]!
  creationTime: Float
  modelType: ModelType!
  assetCategory: AssetCategory
  segment(tags: [SegmentTagFilter!]): Segment
  segments(offset: Int = 0, limit: Int = 0, filter: SegmentFilter, sort: SegmentSort): [Segment!]!
  output(name: String!): Feature
  outputs: [Feature!]!
  filteredOutputs(
    offset: Int = 0
    limit: Int = 0
    filter: FeatureFilter!
    sort: FilteredFeaturesSort
  ): FilteredFeatures!
  feature(name: String!): Feature
  features(offset: Int = 0, limit: Int = 0): [Feature!]!
    @deprecated(
      reason: "This query returns ALL features in a dataset, which can be thousands. Please use 'filteredFeatures' query instead."
    )
  filteredFeatures(
    offset: Int = 0
    limit: Int = 0
    filter: FeatureFilter!
    sort: FilteredFeaturesSort
  ): FilteredFeatures!
  batch(datasetTimestamp: Float!): BatchMetadata
  """
  Fetches the dataset-level metadata by time range or from the specified timestamps.
  If the `timestamps` argument is passed, it will be prioritized over the `from/to` args.
  We probably shouldn't pass more than a couple timestamps at a time. For large queries, use a time range :)
  """
  batches(from: Float = 0, to: Float, timestamps: [Float!]): [BatchMetadata!]!
  batchDateRanges(timestamps: [Float!]!): [DateRange!]!
  alerts(filter: EventFilter!): [DataQualityEvent!]!
    @deprecated(reason: "This query serves Monitor V2 data. Use 'anomalies' query instead")
  alertCountsV2(
    fromTimestamp: Float!
    toTimestamp: Float
    groupBy: AnomalyCountGroupBy
    filter: AnomalyOptionalFilter
    granularityInclusion: GranularityInclusion
  ): AlertCategoryCounts @deprecated(reason: "Use anomalyCounts instead - same query, but clearer naming.")
  latestAlert: DataQualityEvent
    @deprecated(reason: "This query serves Monitor V2 data. Use 'latestAnomaly' query instead")
  latestAnomaly(monitorIds: [String!], analyzerIds: [String!]): AnalysisResult
    @deprecated(reason: "No longer supported. Use 'latestAnomalyTimestamp' instead")
  """
  Returns the timestamp of the latest anomaly, if one exists
  """
  latestAnomalyTimestamp(monitorIds: [String!], analyzerIds: [String!]): Float
  events(filter: EventFilter!): [DataQualityEvent!]!
    @deprecated(reason: "This query serves Monitor V2 data. Use 'analysisResults' query instead")
  monitorConfigAuditLogs(from: Float, to: Float): [AuditLog!]!
    @cacheControl(maxAge: 0)
    @deprecated(reason: "These are Monitor V2 audit logs. These don't work with MV3.")
  batchFrequency: TimePeriod!
  totalFeatures(fromTimestamp: Float = 0, toTimestamp: Float): Int! @deprecated(reason: "Use entitySchema")
  totalSegments: Int!
  totalFilteredSegments(filter: SegmentFilter): Int!
  featureCounts: FeatureCounts @deprecated(reason: "Use entitySchema")

  """
  Available reference profiles that have been uploaded for this dataset
  """
  referenceProfiles(from: Float, to: Float, profileIds: [String!]): [ReferenceProfile!]
  """
  Individual profiles that have been uploaded for this dataset
  """
  individualProfileList(from: Float!, to: Float!, offset: Int, limit: Int): [IndividualProfileItem!]
  """
  Individual profiles that have been uploaded for this dataset
  """
  individualProfiles(retrievalTokens: [String!]!): [IndividualProfile!]
  """
  Constraints list (analyzers json string config) for this dataset
  """
  constraintsList: [String!]
  """
  Information about data availability for this dataset
  """
  dataAvailability: DataAvailability
  """
  Date range of data lineage for this dataset with start and end timestamps fitting the batch bucket
  """
  dataLineage: DataLineage
  """
  Information about entity schema for this dataset
  """
  entitySchema: EntitySchema
  """
  Profile insights for this model
  """
  insights(batchProfileTimestamp: Float, referenceProfileId: String, tags: [SegmentTagFilter!]): [InsightEntry!]
}

type FeatureSchema {
  inferredType: FeatureType!
  isDiscrete: Boolean!
  description: String
  tags: [String!]
}

type EntityColumnSchema {
  name: String!
  inferredType: FeatureType!
  isDiscrete: Boolean!
  description: String
  tags: [String!]
}

type Feature {
  id: String!
  alertCounts(fromTimestamp: Float, toTimestamp: Float): AlertCount @deprecated(reason: "Use alertCountsV2 instead")
  alertCountsV2(
    fromTimestamp: Float!
    toTimestamp: Float
    groupBy: AnomalyCountGroupBy
    filter: AnomalyOptionalFilter
    granularityInclusion: GranularityInclusion
  ): AlertCategoryCounts @deprecated(reason: "Use anomalyCounts instead - same query, but clearer naming.")
  modelName: String!
  modelTimePeriod: TimePeriod!
  modelId: String!
  tags: [SegmentTag!]!
  name: String!
  """
  Returns dataset profiles/sketches associated with the feature.

  Set histogramSplitPoints to specify the desired histogram bin edges.
  NOTE: min and max will be added automatically at query time, because they depend on the profile for which the histogram will be generated. These split points should not include min/max.
  E.g., if you'd like to split data into bins with edges [min, 5, 10, max], set this argument to [5, 10]
  """
  sketches(from: Float!, to: Float, histogramSplitPoints: [Float!]): [FeatureSketch!]!
  alerts(filter: EventFilter!): [DataQualityEvent!]!
    @deprecated(reason: "This query serves Monitor V2 data. Use 'anomalies' query instead")
  latestAlert: DataQualityEvent
    @deprecated(reason: "This query serves Monitor V2 data. Use 'latestAnomaly' query instead")
  latestAnomaly(monitorIds: [String!], analyzerIds: [String!]): AnalysisResult
    @deprecated(reason: "No longer supported. Use 'latestAnomalyTimestamp' instead")
  """
  Returns the timestamp of the latest anomaly, if one exists
  """
  latestAnomalyTimestamp(monitorIds: [String!], analyzerIds: [String!]): Float
  events(filter: EventFilter!): [DataQualityEvent!]!
    @deprecated(reason: "This query serves Monitor V2 data. Use 'analysisResults' query instead")
  baselineSketch: FeatureSketch
    @deprecated(
      reason: "To get schema information for a feature, please use the new `schema` field. The baseline sketch may not return all fields specified on the FeatureSketch type."
    )
  """
  Returns schema information for the feature (type, discreteness, etc)
  """
  schema: FeatureSchema
}

type AlertCount {
  total: Float!
  nullFraction: Float!
  distribution: Float!
  uniqueness: Float!
  dataType: Float!
  thresholdBased: Float!
  unknown: Float!
}

enum AlertCategory {
  Ingestion
  DataQuality
  DataDrift
  Performance
  Unknown
}

type AlertCategoryCount {
  category: AlertCategory!
  count: Float!
  metric: AnalysisMetric
}

type GroupedAlertBatch {
  """
  Alert timestamp
  """
  timestamp: Float!
  """
  Counts of alerts by category
  """
  counts: [AlertCategoryCount!]!
}

type AlertCategoryCounts {
  """
  Total alerts within range, broken down by category
  """
  totals: [AlertCategoryCount!]!
  """
  Alerts by category and timestamp
  """
  timeseries: [GroupedAlertBatch!]!
}

# this must match the corresponding WhyLogs feature type enum
enum FeatureType {
  UNKNOWN
  NULL
  FRACTION
  INTEGER
  BOOLEAN
  TEXT
}

input LimitSpec {
  offset: Int
  limit: Int
  sortDirection: SortDirection
}
