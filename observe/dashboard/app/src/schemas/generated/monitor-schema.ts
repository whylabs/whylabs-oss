/* tslint:disable */
/* eslint-disable */
/**
 * The file ./src/schemas/generated/monitor-schema.ts is generated by core-types-ts on behalf of typeconv, DO NOT EDIT.
 * For more information, see:
 *  - {@link https://github.com/grantila/core-types-ts}
 *  - {@link https://github.com/grantila/typeconv}
 */

/**
 * Metadata for a top-level objects such as monitors, analyzers, and schema.
 *
 * This object is managed by WhyLabs. Any user-provided values will be ignored on WhyLabs side.
 */
export interface Metadata {
    /** A monotonically increasing numer that indicates the version of the object. */
    version: number;
    /** The version of the schema. Currently the accepted value is 1. */
    schemaVersion?: number;
    /** Last updated timestamp */
    updatedTimestamp: number;
    /** The author of the change. It can be an API Key ID, a user ID, or a WhyLabs system ID. */
    author: string;
    /** A description of the object */
    description?: string;
}

/** Supported granularity. */
export type Granularity = "hourly" | "daily" | "weekly" | "monthly";

/** Classifying the type. */
export type ColumnDiscreteness = "discrete" | "continuous";

/** Options for configuring data type for a column. */
export type ColumnDataType = "integral" | "fractional" | "bool" | "string" | "unknown" | null;

/**
 * Schema configuration for a column.
 *
 * Should be generated by WhyLabs originally but can be overridden by users.
 */
export interface ColumnSchema {
    discreteness: ColumnDiscreteness;
    dataType: ColumnDataType;
    /**
     * We can classify these columns into various grouping. Currently we only support 'input' and 'output'
     *
     * @default
     *     input
     */
    classifier?: string;
}

/** Schema definition of an entity. */
export interface EntitySchema {
    metadata?: Metadata;
    /** Schema configuration for the entity */
    columns: {
        [key: string]: ColumnSchema;
    };
}

/**
 * Object that specifies column weights.
 *
 * - By default, the weight of a column is None (unspecified)
 * - If the weight is unspecified, the column is EXCLUDED when you perform a filter/sort by weight
 * - For sorting, unweighted column take the LEAST PRECEDENCE, meaning that weight column have higher priorities
 * - They are not hierarchical: if a segment weight config is specified and a column does not have a weight in that
 * config, we will not use any hierarchy to resolve the value. It will be None
 * - Order of unweighted column is undefined.
 */
export interface WeightConfig {
    /** Weights of the features */
    weights: {
        [key: string]: number;
    };
}

/** A single tag key value pair for a segment. */
export interface SegmentTag {
    key: string;
    value: string;
}

/**
 * A segment is a list of tags.
 *
 * We normalize these in the backend.
 */
export interface Segment {
    /** List of tags that define the specific segment */
    tags: SegmentTag[];
}

/** Object that specifies column weights for a segment. */
export interface SegmentWeightConfig {
    /** Weights of the features */
    weights: {
        [key: string]: number;
    };
    segment?: Segment;
}

/** Entity weight configurations. */
export interface EntityWeights {
    metadata?: Metadata;
    defaultWeights?: WeightConfig;
    /** Optional. Segment-specific weights. Use this if you want to override the defaultWeights. Note thatthere might be a case where a segment fields are weighted without specifying the default weights */
    segmentWeights?: SegmentWeightConfig[];
}

/** Support for a specific time range. */
export interface TimeRange {
    /** Inclusive. Start time of a time range. */
    start: string;
    /** Exclusive. End time of a time range. */
    end: string;
}

/** Support for scheduling. */
export interface CronSchedule {
    type: "cron";
    /** Cron expression */
    cron: string;
    /** The ranges of dates during which this Analyzer is NOT run. */
    exclusionRanges?: TimeRange[];
}

/** Support for scheduling based on a predefined cadence. */
export interface FixedCadenceSchedule {
    type: "fixed";
    /** Frequency to run the analyzer or monitor, based on UTC time. The monitor will run at the start of the cadence with some SLA depending on the customer tiers. */
    cadence: "hourly" | "daily" | "weekly" | "monthly";
    /** Ranges of dates during which this Analyzer is NOT run. */
    exclusionRanges?: TimeRange[];
}

/** Standard column groupings. */
export type ColumnGroups = "group:continuous" | "group:discrete" | "group:input" | "group:output";

/** Define the matrix of columns and segments to fan out for monitoring. */
export interface ColumnMatrix {
    /** List of targeted segments. If not set, default to the overall segment */
    segments?: Segment[];
    /** List of segments to be excluded */
    excludeSegments?: Segment[];
    type: "column";
    /** List of allowed fields/features/columns. Could be a grouping as well. */
    include?: (ColumnGroups | string)[];
    /** List of blocked fields/features/columns. Could be a grouping as well. This setting is evaluated AFTER the 'include' field and thus should be used with caution. */
    exclude?: (ColumnGroups | string)[];
    /** The unique profile ID for the reference profile */
    profileId?: string;
}

/**
 * Define the matrix of fields and segments to fan out for monitoring.
 *
 * .
 */
export interface DatasetMatrix {
    /** List of targeted segments. If not set, default to the overall segment */
    segments?: Segment[];
    /** List of segments to be excluded */
    excludeSegments?: Segment[];
    /**
     * Must be 'dataset' level
     *
     * @default
     *     dataset
     */
    type?: "dataset";
}

/** Conjunction (ANDs) composite analyzer joining multiple analyzers */
export interface ConjunctionConfig {
    type: "conjunction";
    /** The corresponding analyzer IDs for the conjunction. */
    analyzerIds: string[];
}

/** Disjunction (ORs) composite analyzer joining multiple analyzers */
export interface DisjunctionConfig {
    type: "disjunction";
    /** The corresponding analyzer IDs for the conjunction. */
    analyzerIds: string[];
}

/** Metrics that are applicable at the dataset level. */
export type DatasetMetric = "profile.count" | "profile.last_ingestion_time" | "profile.first_ingestion_time" | "column_row_count_sum" | "shape_column_count" | "shape_row_count" | "input.count" | "output.count" | "classification.f1" | "classification.precision" | "classification.recall" | "classification.accuracy" | "classification.fpr" | "classification.auroc" | "regression.mse" | "regression.mae" | "regression.rmse";

/** Simple column metrics that are basically just a single number. */
export type SimpleColumnMetric = "count" | "median" | "max" | "min" | "mean" | "stddev" | "variance" | "unique_upper" | "unique_upper_ratio" | "unique_est" | "unique_est_ratio" | "unique_lower" | "unique_lower_ratio" | "count_bool" | "count_bool_ratio" | "count_integral" | "count_integral_ratio" | "count_fractional" | "count_fractional_ratio" | "count_string" | "count_string_ratio" | "count_null" | "count_null_ratio" | "inferred_data_type" | "quantile_5" | "quantile_75" | "quantile_25" | "quantile_90" | "quantile_95" | "quantile_99";

/** Whether to use the absolute difference or the percentage to calculate the difference. */
export type DiffMode = "abs" | "pct";

/**
 * Threshold Type declaring the upper and lower bound.
 *
 * By default an anomaly will be generated when the target is above or below the baseline
 * by the specified threshold.
 *
 * If its only desirable to alert when the target is above the
 * baseline and not the other way around, specify upper for your ThresholdType.
 */
export type ThresholdType = "lower" | "upper";

/**
 * A dynamic trailing window.
 *
 * This is useful if you don't have a static baseline to monitor against. This is the default mode for most
 * monitors.
 */
export interface TrailingWindowBaseline {
    /** The unique ID of an dataset. This is specific to WhyLabs. If the dataset ID does not exist, user will get a validation exception when saving the config with WhyLabs API */
    datasetId?: string;
    /** Default to false. Whether to use the segment from the target to filter down the baseline */
    inheritSegment?: boolean;
    type: "TrailingWindow";
    /** Window size */
    size: number;
    /** Offset from the current batch for the range of the trailing window. Default to 1 (the previous batch). This means that if set this to 0, the baseline will include the current batch's value, orif we set it o 7, then the window is off by 7. */
    offset?: number;
    /** The list of exclusion ranges */
    exclusionRanges?: TimeRange[];
}

/**
 * A baseline based on a static reference profile.
 *
 * A typical use case is to use a "gold" dataset and upload its profile to WhyLabs. This can be a training dataset
 * as well for an ML model.
 */
export interface ReferenceProfileId {
    /** The unique ID of an dataset. This is specific to WhyLabs. If the dataset ID does not exist, user will get a validation exception when saving the config with WhyLabs API */
    datasetId?: string;
    type: "Reference";
    /** The unique profile ID for the reference profile */
    profileId: string;
}

/**
 * A static time range.
 *
 * Instead of using a single profile or a trailing window, user can lock in a "good" period.
 */
export interface TimeRangeBaseline {
    /** The unique ID of an dataset. This is specific to WhyLabs. If the dataset ID does not exist, user will get a validation exception when saving the config with WhyLabs API */
    datasetId?: string;
    /** Default to false. Whether to use the segment from the target to filter down the baseline */
    inheritSegment?: boolean;
    type: "TimeRange";
    range: TimeRange;
}

/**
 * Using current batch.
 *
 * This is used when you want to use one batch to monitor another batch in a different metric entity.
 */
export interface SingleBatchBaseline {
    /** The unique ID of an dataset. This is specific to WhyLabs. If the dataset ID does not exist, user will get a validation exception when saving the config with WhyLabs API */
    datasetId: string;
    /** Default to false. Whether to use the segment from the target to filter down the baseline */
    inheritSegment?: boolean;
    type: "CurrentBatch";
    /** Offset from the current batch for the baseline. Default to 0 - (the current batch). This means that if this field set this to 0, the baseline be the current batch's value. The dataset fieldis required to be set for this baseline config.Typical use case is to use another entity to monitor against the current entity */
    offset?: number;
}

/** Detecting the differences between two numerical metrics. */
export interface DiffConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    type: "diff";
    mode: DiffMode;
    thresholdType?: ThresholdType;
    /** The minimum threshold that will trigger an anomaly. The monitor detect the difference betweenthe target's metric and the baseline metric. Both of these metrics MUST be in rolled up form */
    threshold: number;
    baseline: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/** Operators for performing a comparison. */
export type ComparisonOperator = "eq" | "gt" | "lt" | "ge" | "le";

/** Expected value: one of these fields must be set. */
export interface ExpectedValue {
    str?: string;
    int?: number;
    float?: number;
}

/**
 * Compare whether the target against either an expect value or against the  baseline.
 *
 * This is useful to detect data type change, for instance.
 */
export interface ComparisonConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    type: "comparison";
    operator: ComparisonOperator;
    expected?: ExpectedValue;
    baseline?: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/** Operators for performing a comparison. */
export type ListComparisonOperator = "in" | "not_in";

/** Compare a target list of values against a baseline list of values. */
export interface ListComparisonConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    type: "list_comparison";
    operator: ListComparisonOperator;
    /** The expected values of the equality. If the value is not set we will extract the corresponding metric from the baseline and perform the comparison */
    expected?: ExpectedValue[];
    baseline?: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/** Operators for performing a comparison. */
export type FrequentStringComparisonOperator = "eq" | "target_includes_all_baseline" | "baseline_includes_all_target";

/** Compare whether target against a list of values. */
export interface FrequentStringComparisonConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: "frequent_items";
    type: "frequent_string_comparison";
    operator: FrequentStringComparisonOperator;
    baseline: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/**
 * Compare whether the target is equal to a value or not.
 *
 * This is useful to detect data type change, for instance.
 */
export interface ColumnListChangeConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: "column_list";
    type: "column_list";
    /**
     * @default
     *     ON_ADD_AND_REMOVE
     */
    mode?: "ON_ADD_AND_REMOVE" | "ON_ADD" | "ON_REMOVE";
    /** Ignore these column names. User can specify a list of regex */
    exclude?: string[];
    baseline: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/**
 * Fixed threshold analysis.
 *
 * If user fails to set both upper bound and lower bound, this algorithm becomes a no-op.
 * WhyLabs might enforce the present of either fields in the future.
 */
export interface FixedThresholdsConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    type: "fixed";
    /** Upper bound of the static threshold */
    upper?: number;
    /** Lower bound of the static threshold */
    lower?: number;
}

/**
 * Calculates upper bounds and lower bounds based on stddev from a series of numbers.
 *
 * An analyzer using stddev for a window of time range.
 *
 * This calculation will fall back to Poisson distribution if there is only 1 value in the baseline.
 * For 2 values, we use the formula sqrt((x_i - avg(x))^2 / n - 1)
 */
export interface StddevConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    /** Capping the threshold by this value. This value only becomes effective if the calculated upper threshold from the calculation is greater than this value. */
    maxUpperThreshold?: number;
    /** Capping the minimum threshold by this value. This value only becomes effective if the calculated lower threshold from the calculation is lesser than this value */
    minLowerThreshold?: number;
    thresholdType?: ThresholdType;
    type: "stddev";
    /**
     * The multiplier used with stddev to build the upper and lower bounds.
     *
     * @default
     *     3
     */
    factor?: number;
    /**
     * Minimum number of batches that is required
     *
     * @default
     *     1
     */
    minBatchSize?: number;
    baseline: TrailingWindowBaseline | TimeRangeBaseline | ReferenceProfileId;
}

/**
 * An analyzer using stddev for a window of time range.
 *
 * This analysis will detect whether the data drifts or not. By default, we use hellinger distance with a threshold
 * of 0.7.
 */
export interface DriftConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: "histogram" | "frequent_items";
    type: "drift";
    /**
     * The algorithm to use when calculating drift.
     *
     * @default
     *     hellinger
     */
    algorithm?: "hellinger" | "jensenshannon" | "kl_divergence" | "psi";
    /**
     * The threshold for the distance algorithm. Depending on the algorithm, this thresholdis used for greater than or less than comparison.
     *
     * @default
     *     0.7
     */
    threshold?: number;
    /**
     * Minimum number of batches that is required
     *
     * @default
     *     1
     */
    minBatchSize?: number;
    baseline: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
}

/** Specify the algorithm type. */
export type AlgorithmType = "expected" | "column_list" | "comparison" | "conjunction" | "disjunction" | "list_comparison" | "frequent_string_comparison" | "diff" | "drift" | "stddev" | "seasonal" | "fixed" | "experimental";

/** Experimental algorithm that is not standardized by the above ones yet. */
export interface ExperimentalConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    type: "experimental";
    /** The implementation of an experimental config */
    implementation: string;
    baseline: TrailingWindowBaseline | ReferenceProfileId | TimeRangeBaseline | SingleBatchBaseline;
    stub?: AlgorithmType;
}

/**
 * An analyzer using stddev for a window of time range.
 *
 * This will fall back to Poisson distribution if there is only 1 value in the baseline.
 *
 * This only works with TrailingWindow baseline (TODO: add backend validation)
 */
export interface SeasonalConfig {
    /** The schema version of an algorithm. Typically this value is not required. */
    schemaVersion?: number;
    /** Extra parameters for the algorithm */
    params?: {
        [key: string]: string;
    };
    metric: DatasetMetric | SimpleColumnMetric | string;
    /** Capping the threshold by this value. This value only becomes effective if the calculated upper threshold from the calculation is greater than this value. */
    maxUpperThreshold?: number;
    /** Capping the minimum threshold by this value. This value only becomes effective if the calculated lower threshold from the calculation is lesser than this value */
    minLowerThreshold?: number;
    thresholdType?: ThresholdType;
    type: "seasonal";
    /**
     * The algorithm implementation for seasonal analysis
     *
     * @default
     *     arima
     */
    algorithm?: "arima";
    /**
     * Minimum number of batches that is required
     *
     * @default
     *     30
     */
    minBatchSize?: number;
    /**
     * significance level for the confidence interval produced around predictions. If 0.05 then the algorithm will calculate a 95% confidence interval around predictions
     *
     * @default
     *     0.05
     */
    alpha?: number;
    baseline: TrailingWindowBaseline;
    /** Ranges of time where we will apply standard deviation for confidence intervals rather than the confidence interval from the algorithm. This is to prevent data from specialevents from making the bands very wide for timeseries-based predictions. */
    stddevTimeRanges?: TimeRange[];
    /** Maxinum number of data points to consider for calculating stddev. These are the data pointspreceeding the target batch. */
    stddevMaxBatchSize?: number;
    /**
     * The multiplier factor for calculating upper bounds and lower bounds from the prediction.
     *
     * @default
     *     1
     */
    stddevFactor?: number;
}

/**
 * Configuration for running an analysis.
 *
 * An analysis targets a metric (note that a metric could be a complex object) for one or multiple fields in
 * one or multiple segments. The output is a list of 'anomalies' that might show issues with data.
 */
export interface Analyzer {
    metadata?: Metadata;
    /** A unique, human readable ID for an analyzer. Can only contain alpha numeric characters, underscores and dashes */
    id?: string;
    /** A display name for the analyzer if view through WhyLabs UI. Can only contain dashes, underscores,spaces, and alphanumeric characters */
    displayName?: string;
    /** A list of tags that are associated with the analyzer. */
    tags?: string[];
    /** By default analyzers compare a baseline to a single target bucket who's size aligns with the dataset granularity. For example a daily dataset will use targets with a size of one day. Some datasets with a lot of fluctuation can lead to noisy monitors. One approach to making analyzers less noisy in such a scenario is to increase the targetSize to average across more than a single bucket. */
    targetSize?: number;
    schedule?: CronSchedule | FixedCadenceSchedule;
    /** Whether the analyzer is disabled. This allows user to keep the configurationaround without having to delete the analyzer config */
    disabled?: boolean;
    /** For customers with individual profile storage enabled on their account (contact us), this allows a user to monitor individual profiles without rolling them up. When enabled, analysis will be timestamped 1:1 with the profile's dataset timestamp rather than being truncated to the dataset granularity. */
    disableTargetRollup?: boolean;
    targetMatrix?: ColumnMatrix | DatasetMatrix;
    /** ISO 8610 duration format. The duration determines how fast data is ready for the monitor. For example, if your pipeline takes 2 days to deliver profiles to WhyLabs, the value should beP2D. Note that this value will be used to evaluate missing data as well */
    dataReadinessDuration?: string;
    /** ISO 8610 duration format. Specifies the duration that the monitor will wait from the last timea profile arrives Any batch involved in the calculation must have received the last profile by the duration. */
    batchCoolDownPeriod?: string;
    /** ISO 8610 duration format. How far back an analyzer will attempt to backfill late data. Note that we will only backfill batches not previously analyzed. If the batch was already analyzed, even with partial data, the backfill will ignore the new data unless you trigger an explicit backfill request. We support 48 hours for hourly data, 30 days for daily data, and 6 months for monthly data. */
    backfillGracePeriodDuration?: string;
    config: ConjunctionConfig | DisjunctionConfig | DiffConfig | ComparisonConfig | ListComparisonConfig | FrequentStringComparisonConfig | ColumnListChangeConfig | FixedThresholdsConfig | StddevConfig | DriftConfig | ExperimentalConfig | SeasonalConfig;
}

/** Schedule the monitor to run immediately. */
export interface ImmediateSchedule {
    type: "immediate";
}

/** Filter the anomalies based on certain criteria. If the alerts are filtered down to 0, the monitor won't fire. */
export interface AnomalyFilter {
    /** If set, we only include anomalies from these columns */
    includeColumns?: string[];
    /** If set, we will exclude anomalies from these columns. This is applied AFTER the includeColumns */
    excludeColumns?: string[];
    /** We will include only features with weights greater than or equal to this value. NOT SUPPORTED YET */
    minWeight?: number;
    /** We will include only features with weights less thanor equal to this value. NOT SUPPORTED YET */
    maxWeight?: number;
    /** Include only features ranked greater than or equal tothis value by weight. If features have the same weight, we order them alphabetically. NOT SUPPORTED YET */
    minRankByWeight?: number;
    /** Include only features ranked less than or equal tothis value by weight. If features have the same weight, we order them alphabetically. NOT SUPPORTED YET */
    maxRankByWeight?: number;
    /** Only fire the monitor if the total weights of the alerts (based on feature weights) is greater than or equal to this value. NOT SUPPORTED YET */
    minTotalWeight?: number;
    /** Only fire the monitor if the total weights of the alerts (based on feature weights) is less than or equal to this value. NOT SUPPORTED YET */
    maxTotalWeight?: number;
    /** If the total alert count is less than this value, the monitor won't fire. */
    minAlertCount?: number;
    /** If the total alert count is greater than this value, the monitor won't fire. */
    maxAlertCount?: number;
    /** Metrics to filter by. NOT SUPPORTED YET */
    includeMetrics?: string[];
}

/** Config mode that indicates the monitor will send out individual messages per anomaly. */
export interface EveryAnomalyMode {
    type: "EVERY_ANOMALY";
    filter?: AnomalyFilter;
}

/** Enable the ability to group digest by various fields. */
export type DigestModeGrouping = "byColumn" | "byDataset" | "byAnalyzer" | "byDay" | "byHour";

/** Config mode that indicates the monitor will send out a digest message. */
export interface DigestMode {
    type: "DIGEST";
    filter?: AnomalyFilter;
    /** Optional for Immediate digest, required for Scheduled digest. The earliest creation timestamp that we will filter by to build the digest. ISO 8601 format for timedelta. */
    creationTimeOffset?: string;
    /** Optional for Immediate digest, required for Scheduled digest. The earliest dataset timestamp that we will filter by in the digest */
    datasetTimestampOffset?: string;
    /** Default is None.If this is set, we will group alerts by these groupings and emit multiple messages per group. */
    groupBy?: DigestModeGrouping[];
}

/** Actions that are configured at the team/organization level. */
export interface GlobalAction {
    type: "global";
    /** The unique action ID in the platform */
    target: string;
}

/** Action to send an email. */
export interface SendEmail {
    type: "email";
    /** Destination email */
    target: string;
}

/** Action to send a Slack webhook. */
export interface SlackWebhook {
    type: "slack";
    /** The Slack webhook */
    target: string;
}

/** Action to send a Slack webhook. */
export interface RawWebhook {
    type: "raw";
    /** Sending raw unformatted message in JSON format to a webhook */
    target: string;
}

/** Customer specified monitor configs. */
export interface Monitor {
    metadata?: Metadata;
    /** A human-readable alias for a monitor. Must be readable */
    id?: string;
    /** A display name for the monitor if view through WhyLabs UI. Can only contain dashes, underscores,spaces, and alphanumeric characters */
    displayName?: string;
    /** A list of tags that are associated with the monitor. */
    tags?: string[];
    /** The corresponding analyzer ID. Even though it's plural, we only support one analyzer at the moment */
    analyzerIds: string[];
    schedule: FixedCadenceSchedule | CronSchedule | ImmediateSchedule;
    /** Whether the monitor is enabled or not */
    disabled?: boolean;
    /**
     * The severity of the monitor messages
     *
     * @default
     *     3
     */
    severity?: number;
    mode: EveryAnomalyMode | DigestMode;
    /** List of destination for the outgoing messages */
    actions: (GlobalAction | SendEmail | SlackWebhook | RawWebhook)[];
}
