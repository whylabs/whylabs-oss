## Overview

Dataservice is a backend service designed to store/query/manage/monitor statistical profiles generated by the whylogs client library. The backend services
are primarily java/JVM using Postgres as the database. This project has an Apache2 licence.

## Postgres

This project relies on two postgres extensions to support apache datasketches and to work with timeseries data efficiently. The
Apache Datasketch extension is unfortunately, at the time of writing, unsupported by popular cloud vendors such an AWS RDS. This necessitates running
your own Postgres infra to enable running extensions.

### Extensions

#### Apache Datasketch

Core to whylogs is the [Apache Datasketch](https://datasketches.apache.org/) library. While stored as byte arrays, the ability to
query and merge datasketches is provided by the [Postgres Datasketches](https://github.com/apache/datasketches-postgresql) extension. This
must be installed in the docker container. 

#### TimescaleDB

[TimescaleDB](www.timescale.com) is an open source extension for Postgres which makes working with timeseries data faster and easier. This
project uses it for time partitioning tables and automatic data retention. This must be installed in the docker container. The Apache2 licenced
edition will suffice, but there are a number of capabilities that can be unlocked via the community edition grepping the codebase for
"Disabling to get timescaledb back to apache2 licence". You can find more details about the appropriate TimescaleDB license [here](https://www.timescale.com/legal/licenses).

#### Whylogs

[whylogs](https://github.com/whylabs/whylogs) while optional, installing the whylogs python library enables this project to query and aggregate
model level profile data (eg probabilistic confusion matrix).

### Container/K8

The most common way to run a customized Postgres container is with a Kubernetes operator. This repository contains source code for a Postgres 14 container that can be deployed with Cloudnative Postgres.

### Recommended Setup

This project breaks out read-only and write-only workloads onto separate connection pools to blend nicely with a traditional Primary->Replica style
database architecture. Read-only APIs query the database replica enabling high availability via running multiple database replicas and load
balancing between them. Load balancing multiple read replicas in the Postgres world is typically (as is the case with the Cloudnative Postgres operator) achieved
via [PgBouncer](https://www.pgbouncer.org/). You'll typically run one pg_bouncer instance per connection pool.


### Connection pooling

Connection pools can be configured to hit individual PgBouncer hosts via environment variables. For example:

```
POSTGRES_BULK=dev-postgres-pooler;POSTGRES_REPL=postgres-primary-replica-pooler.datastack.svc.cluster.local.;DB_PASSWORD=*****
```

See application.yaml in the dataservice module for more details on configuration options.

### Database Schema

Database schema changes are managed by liquibase and automatically rolled out upon deploy. This can be enabled/disabled via the DISABLE_LIQUIDBASE environment variable. This
will handle the creation of all tables and indices needed.

### Postgres Storage

When running Postgres with CNPG Operator, data is expected to reside on EBS style block storage. The
operator handles operations such as reattaching volumes when performing rolling deploys, but there's additional concerns
to be aware of.

Freeing up disk space in Postgres is nuanced as simply deleting old data will not release disk space to the operating
system automatically. Options for freeing up disk space include:

* pg_repack: Lock friendly, but at the time of writing, incompatible with timescaledb hypertables
* vacuum full: Read exclusive lock, requires downtime
* [timescaledb retention policy](https://docs.timescale.com/use-timescale/latest/data-retention/create-a-retention-policy/): Best of both worlds. Lock friendly, timescaledb compatible, but non-surgical. Ideal for purging data older data on a table.

### Postgres Monitoring

It's recommended to use an APM tool to keep an eye on Postgres for optimal performance.

## Workspace set up

* We use [Google Java Format](https://github.com/google/google-java-format) to manage our code
  formatting

* Install the git hook to apply the code format every time you commit:
  ```
  make init
  ```

* You can check the uncommitted code with:
  ```
  make lint
  ```

* You can fix any style issues without committing with:
  ```
  make lint-fix
  ```

* The code format is checked in the repo
    * You can install
      the [Google Java Format](https://plugins.jetbrains.com/plugin/8527-google-java-format)
      plugin for IntelliJ
* It's recommended that you
  install [Save Actions](https://plugins.jetbrains.com/plugin/7642-save-actions/)
  that will run code formatting on save.
* Install the python sdk into intellij https://plugins.jetbrains.com/plugin/631-python and then file->project structure->sdks, add python and be sure to name it "Poetry (whylabs-processing-core)", then open facets, and point the python facet to your sdk


## Testing

* Run overall testing with:

```
make test
```