package ai.whylabs.dataservice.requests;

import ai.whylabs.dataservice.enums.GranularityInclusion;
import ai.whylabs.dataservice.enums.ParentChildScope;
import com.fasterxml.jackson.annotation.JsonPropertyDescription;
import io.swagger.v3.oas.annotations.media.Schema;
import java.util.List;
import lombok.Data;
import lombok.experimental.FieldNameConstants;
import org.joda.time.Interval;

@FieldNameConstants
@Data
public class GetSegmentAnomalyCountsRequest {
  @JsonPropertyDescription("Required, orgId")
  @Schema(required = true)
  private String orgId;

  @JsonPropertyDescription("Required, datasetId")
  @Schema(required = true)
  private String datasetId;

  @JsonPropertyDescription(
      "Required, return anomalies within this ISO-8601 time period,\ninclusive of start and exclusive of end point.\ne.g. \"2022-07-01T00:00:00.000Z/P30D\" or \"2022-07-01T00:00:00.000Z/2022-07-01T00:00:00.000Z\"")
  @Schema(required = true, type = "string")
  private Interval interval; //  ISO 8601 formatted interval

  @JsonPropertyDescription("List of column names to search for")
  @Schema(required = false)
  private List<String> columnNames;

  @JsonPropertyDescription(
      "Analysis can't be rolled up, so one generally wants to look at either analysis at the bucket level or the individual level")
  @Schema(required = false)
  private GranularityInclusion granularityInclusion = GranularityInclusion.BOTH;

  @JsonPropertyDescription(
      "Optional filter to query for just parent analyzers, just child analyzers, or both")
  @Schema(required = false)
  private ParentChildScope parentChildScope = ParentChildScope.BOTH;

  @JsonPropertyDescription("Read analysis generated by the PG backed monitors")
  private boolean readPgMonitor = false;
}
